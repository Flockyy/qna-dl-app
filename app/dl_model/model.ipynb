{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CamembertModel(\n",
       "  (embeddings): CamembertEmbeddings(\n",
       "    (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): CamembertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x CamembertLayer(\n",
       "        (attention): CamembertAttention(\n",
       "          (self): CamembertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): CamembertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): CamembertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): CamembertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): CamembertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import CamembertModel, CamembertTokenizer\n",
    "\n",
    "# You can replace \"camembert-base\" with any other model from the table, e.g. \"camembert/camembert-large\".\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "camembert = CamembertModel.from_pretrained(\"camembert-base\")\n",
    "\n",
    "camembert.eval()  # disable dropout (or leave in train mode to finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.4909115433692932,\n",
       "  'token': 7200,\n",
       "  'token_str': 'délicieux',\n",
       "  'sequence': 'Le camembert est délicieux :)'},\n",
       " {'score': 0.10556957125663757,\n",
       "  'token': 2183,\n",
       "  'token_str': 'excellent',\n",
       "  'sequence': 'Le camembert est excellent :)'},\n",
       " {'score': 0.03453313931822777,\n",
       "  'token': 26202,\n",
       "  'token_str': 'succulent',\n",
       "  'sequence': 'Le camembert est succulent :)'},\n",
       " {'score': 0.033031292259693146,\n",
       "  'token': 528,\n",
       "  'token_str': 'meilleur',\n",
       "  'sequence': 'Le camembert est meilleur :)'},\n",
       " {'score': 0.030076364055275917,\n",
       "  'token': 1654,\n",
       "  'token_str': 'parfait',\n",
       "  'sequence': 'Le camembert est parfait :)'}]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline \n",
    "\n",
    "camembert_fill_mask  = pipeline(\"fill-mask\", model=\"camembert-base\", tokenizer=\"camembert-base\")\n",
    "results = camembert_fill_mask(\"Le camembert est <mask> :)\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 768])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize in sub-words with SentencePiece\n",
    "tokenized_sentence = tokenizer.tokenize(\"J'aime le camembert !\")\n",
    "# ['▁J', \"'\", 'aime', '▁le', '▁ca', 'member', 't', '▁!'] \n",
    "\n",
    "# 1-hot encode and add special starting and end tokens \n",
    "encoded_sentence = tokenizer.encode(tokenized_sentence)\n",
    "# [5, 121, 11, 660, 16, 730, 25543, 110, 83, 6] \n",
    "# NB: Can be done in one step : tokenize.encode(\"J'aime le camembert !\")\n",
    "\n",
    "# Feed tokens to Camembert as a torch tensor (batch dim 1)\n",
    "encoded_sentence = torch.tensor(encoded_sentence).unsqueeze(0)\n",
    "embeddings, all_layer_embeddings = camembert(encoded_sentence, return_dict=False)\n",
    "embeddings.detach()\n",
    "embeddings.size()\n",
    "# torch.Size([1, 10, 768])\n",
    "# tensor([[[-0.0254,  0.0235,  0.1027,  ..., -0.1459, -0.0205, -0.0116],\n",
    "#         [ 0.0606, -0.1811, -0.0418,  ..., -0.1815,  0.0880, -0.0766],\n",
    "#         [-0.1561, -0.1127,  0.2687,  ..., -0.0648,  0.0249,  0.0446],\n",
    "#         ...,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import CamembertConfig\n",
    "# (Need to reload the model with new config)\n",
    "config = CamembertConfig.from_pretrained(\"camembert-base\", output_hidden_states=True)\n",
    "camembert = CamembertModel.from_pretrained(\"camembert-base\", config=config)\n",
    "\n",
    "embeddings, _, all_layer_embeddings = camembert(encoded_sentence)\n",
    "#  all_layer_embeddings list of len(all_layer_embeddings) == 13 (input embedding layer + 12 self attention layers)\n",
    "\n",
    "all_layer_embeddings[1]\n",
    "# layer 5 contextual embedding : size torch.Size([1, 10, 768])\n",
    "#tensor([[[-0.0032,  0.0075,  0.0040,  ..., -0.0025, -0.0178, -0.0210],\n",
    "#         [-0.0996, -0.1474,  0.1057,  ..., -0.0278,  0.1690, -0.2982],\n",
    "#         [ 0.0557, -0.0588,  0.0547,  ..., -0.0726, -0.0867,  0.0699],\n",
    "#         ...,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"intents\": [\n",
    "{\"tag\": \"greeting\",\n",
    " \"responses\": [\"Salut partenaire!\", \"Salut\", \"Comment ça va?\",   \"Coucou!\", \"Ça va?\"]},\n",
    "{\"tag\": \"age\",\n",
    " \"responses\": [\"J'ai 27 ans\", \"Je suis né en 1995\", \"Je suis né le 25 octobre en 1995\", \"25/10/1995\"]},\n",
    "{\"tag\": \"date\",\n",
    " \"responses\": [\"Je suis disponible tout le week-end\", \"Je n'ai aucun plan pour ce week-end\",  \"Je suis libre ce week-end\"]},\n",
    "{\"tag\": \"name\",\n",
    " \"responses\": [\"Mon nom est Florian\", \"Florian\"]},\n",
    "{\"tag\": \"goodbye\",\n",
    " \"responses\": [\"C'était sympas de parler avec toi\", \"On se voit plus tard\", \"A plus!\"]}\n",
    "]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "import matplotlib.pyplot as plt\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    5,    84,    11,    41,    23, 16320,  1043, 25543,   110,   800,\n",
      "             9,     6],\n",
      "        [    5,    61,  3405,    30,    22,   430,     6,     1,     1,     1,\n",
      "             1,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "text = [\"C'est un model Camembert5.\",\"La donnée est en français\"]\n",
    "# Encode the text\n",
    "encoded_input = tokenizer(text, padding=True,truncation=True, return_tensors='pt')\n",
    "\n",
    "print(encoded_input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In input_ids:\n",
    "\n",
    "5 - Indicates beginning of the sentence\n",
    "\n",
    "6 - Indicates end of the sentence\n",
    "\n",
    "In attention_mask:\n",
    "\n",
    "1 - Actual token\n",
    "\n",
    "0 - Padded token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Que fais tu lundi ?</td>\n",
       "      <td>date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comment comment t'appelles-tu ?</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Salut !</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quel age as-tu ?</td>\n",
       "      <td>age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Je dois y aller</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              text     label\n",
       "0              Que fais tu lundi ?      date\n",
       "1  Comment comment t'appelles-tu ?      name\n",
       "2                          Salut !  greeting\n",
       "3                 Quel age as-tu ?       age\n",
       "4                  Je dois y aller   goodbye"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'text': [\"Que fais tu lundi ?\", \"Comment comment t'appelles-tu ?\", \"Salut !\", \"Quel age as-tu ?\", \"Je dois y aller\"], 'label': [\"date\", \"name\", \"greeting\", \"age\", \"goodbye\"]}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the labels into encodings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['label'])\n",
    "train_text, train_labels = df['text'], df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in train_text]\n",
    "pd.Series(seq_len).hist(bins = 10)\n",
    "# Based on the histogram we are selecting the max len as 8\n",
    "max_seq_len = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Apprenant\\anaconda3\\envs\\deep-learning\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer(\n",
    "    train_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train set\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "#define a batch size\n",
    "batch_size = 16\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "# DataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAMEMBERT_Arch(nn.Module):\n",
    "   def __init__(self, camembert):      \n",
    "       super(CAMEMBERT_Arch, self).__init__()\n",
    "       self.camembert = camembert \n",
    "      \n",
    "       # dropout layer\n",
    "       self.dropout = nn.Dropout(0.2)\n",
    "      \n",
    "       # relu activation function\n",
    "       self.relu =  nn.ReLU()\n",
    "       # dense layer\n",
    "       self.fc1 = nn.Linear(768,512)\n",
    "       self.fc2 = nn.Linear(512,256)\n",
    "       self.fc3 = nn.Linear(256,5)\n",
    "       #softmax activation function\n",
    "       self.softmax = nn.LogSoftmax(dim=1)\n",
    "       #define the forward pass\n",
    "   def forward(self, sent_id, mask):\n",
    "      #pass the inputs to the model  \n",
    "      cls_hs = self.camembert(sent_id, attention_mask=mask)[0][:,0]\n",
    "      \n",
    "      x = self.fc1(cls_hs)\n",
    "      x = self.relu(x)\n",
    "      x = self.dropout(x)\n",
    "      \n",
    "      x = self.fc2(x)\n",
    "      x = self.relu(x)\n",
    "      x = self.dropout(x)\n",
    "      # output layer\n",
    "      x = self.fc3(x)\n",
    "   \n",
    "      # apply softmax activation\n",
    "      x = self.softmax(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "CAMEMBERT_Arch                                               --\n",
       "├─CamembertModel: 1-1                                        --\n",
       "│    └─CamembertEmbeddings: 2-1                              --\n",
       "│    │    └─Embedding: 3-1                                   (24,579,840)\n",
       "│    │    └─Embedding: 3-2                                   (394,752)\n",
       "│    │    └─Embedding: 3-3                                   (768)\n",
       "│    │    └─LayerNorm: 3-4                                   (1,536)\n",
       "│    │    └─Dropout: 3-5                                     --\n",
       "│    └─CamembertEncoder: 2-2                                 --\n",
       "│    │    └─ModuleList: 3-6                                  (85,054,464)\n",
       "│    └─CamembertPooler: 2-3                                  --\n",
       "│    │    └─Linear: 3-7                                      (590,592)\n",
       "│    │    └─Tanh: 3-8                                        --\n",
       "├─Dropout: 1-2                                               --\n",
       "├─ReLU: 1-3                                                  --\n",
       "├─Linear: 1-4                                                393,728\n",
       "├─Linear: 1-5                                                131,328\n",
       "├─Linear: 1-6                                                1,285\n",
       "├─LogSoftmax: 1-7                                            --\n",
       "=====================================================================================\n",
       "Total params: 111,148,293\n",
       "Trainable params: 526,341\n",
       "Non-trainable params: 110,621,952\n",
       "====================================================================================="
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# freeze all the parameters. This will prevent updating of model weights during fine-tuning.\n",
    "for param in camembert.parameters():\n",
    "      param.requires_grad = False\n",
    "      \n",
    "model = CAMEMBERT_Arch(camembert)\n",
    "# push the model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "from torchinfo import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Apprenant\\anaconda3\\envs\\deep-learning\\Lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-3)\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "# compute the class weights\n",
    "class_wts = compute_class_weight(class_weight = 'balanced', classes = np.unique(train_labels), y = train_labels)\n",
    "print(class_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class weights to tensor\n",
    "weights= torch.tensor(class_wts,dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "\n",
    "# loss function\n",
    "cross_entropy = nn.NLLLoss(weight=weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "# number of training epochs\n",
    "epochs = 30\n",
    "# We can also use learning rate scheduler to achieve better results\n",
    "lr_sch = lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "  \n",
    "  model.train()\n",
    "  total_loss = 0\n",
    "  \n",
    "  # empty list to save model predictions\n",
    "  total_preds=[]\n",
    "  \n",
    "  # iterate over batches\n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "    \n",
    "    # progress update after every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step,    len(train_dataloader)))\n",
    "      \n",
    "    # push the batch to gpu\n",
    "    batch = [r.to(device) for r in batch] \n",
    "    sent_id, mask, labels = batch\n",
    "    # get model predictions for the current batch\n",
    "    preds = model(sent_id, mask)\n",
    "    # compute the loss between actual and predicted values\n",
    "    loss = cross_entropy(preds, labels)\n",
    "  \n",
    "    writer.add_scalar(\"Loss/train\", loss, step)\n",
    "    \n",
    "    # add on to the total loss\n",
    "    total_loss = total_loss + loss.item()\n",
    "    # backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "    # clip the the gradients to 1.0. It helps in preventing the    exploding gradient problem\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    # clear calculated gradients\n",
    "    optimizer.zero_grad()\n",
    "  \n",
    "    # We are not using learning rate scheduler as of now\n",
    "    # lr_sch.step()\n",
    "    # model predictions are stored on GPU. So, push it to CPU\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "    \n",
    "  # compute the training loss of the epoch\n",
    "  avg_loss = total_loss / len(train_dataloader)\n",
    "  writer.flush()\n",
    "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "  #returns the loss and predictions\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 30\n",
      "\n",
      " Epoch 2 / 30\n",
      "\n",
      " Epoch 3 / 30\n",
      "\n",
      " Epoch 4 / 30\n",
      "\n",
      " Epoch 5 / 30\n",
      "\n",
      " Epoch 6 / 30\n",
      "\n",
      " Epoch 7 / 30\n",
      "\n",
      " Epoch 8 / 30\n",
      "\n",
      " Epoch 9 / 30\n",
      "\n",
      " Epoch 10 / 30\n",
      "\n",
      " Epoch 11 / 30\n",
      "\n",
      " Epoch 12 / 30\n",
      "\n",
      " Epoch 13 / 30\n",
      "\n",
      " Epoch 14 / 30\n",
      "\n",
      " Epoch 15 / 30\n",
      "\n",
      " Epoch 16 / 30\n",
      "\n",
      " Epoch 17 / 30\n",
      "\n",
      " Epoch 18 / 30\n",
      "\n",
      " Epoch 19 / 30\n",
      "\n",
      " Epoch 20 / 30\n",
      "\n",
      " Epoch 21 / 30\n",
      "\n",
      " Epoch 22 / 30\n",
      "\n",
      " Epoch 23 / 30\n",
      "\n",
      " Epoch 24 / 30\n",
      "\n",
      " Epoch 25 / 30\n",
      "\n",
      " Epoch 26 / 30\n",
      "\n",
      " Epoch 27 / 30\n",
      "\n",
      " Epoch 28 / 30\n",
      "\n",
      " Epoch 29 / 30\n",
      "\n",
      " Epoch 30 / 30\n",
      "\n",
      "Training Loss: 0.132\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    # it can make your experiment reproducible, similar to set  random seed to all options where there needs a random seed.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "\n",
    "print(f'\\nTraining Loss: {train_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(str):\n",
    " str = re.sub(r'[^a-zA-Z ]+', '', str)\n",
    " test_text = [str]\n",
    " model.eval()\n",
    " \n",
    " tokens_test_data = tokenizer(\n",
    " test_text,\n",
    " max_length = max_seq_len,\n",
    " pad_to_max_length=True,\n",
    " truncation=True,\n",
    " return_token_type_ids=False\n",
    " )\n",
    " test_seq = torch.tensor(tokens_test_data['input_ids'])\n",
    " test_mask = torch.tensor(tokens_test_data['attention_mask'])\n",
    " \n",
    " preds = None\n",
    " with torch.no_grad():\n",
    "   preds = model(test_seq.to(device), test_mask.to(device))\n",
    " preds = preds.detach().cpu().numpy()\n",
    " preds = np.argmax(preds, axis = 1)\n",
    " print(\"Intent Identified: \", le.inverse_transform(preds)[0])\n",
    " return le.inverse_transform(preds)[0]\n",
    "def get_response(message): \n",
    "  intent = get_prediction(message)\n",
    "  for i in data['intents']: \n",
    "    if i[\"tag\"] == intent:\n",
    "      result = random.choice(i[\"responses\"])\n",
    "      break\n",
    "  print(f\"Response : {result}\")\n",
    "  return \"Intent: \"+ intent + '\\n' + \"Response: \" + result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent Identified:  name\n",
      "Response : Mon nom est Florian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Apprenant\\anaconda3\\envs\\deep-learning\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Intent: name\\nResponse: Mon nom est Florian'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(\"Comment tu t'appelles ?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71f86a2391f40680830dad8201e51dc51785baa6652819dd46bb12d3deb241f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
